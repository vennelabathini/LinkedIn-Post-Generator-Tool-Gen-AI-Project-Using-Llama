

# üîó LinkedIn Post Generator ‚Äì GenAI Project (Llama 3.2)

## üìå Project Overview

The **LinkedIn Post Generator** is an end-to-end **Generative AI application** that automatically creates professional LinkedIn posts based on user-selected **topic, language, and length**.
It uses the **Llama 3.2 Large Language Model** with **LangChain** for prompt orchestration and **Streamlit** for an interactive web interface.

This project demonstrates how to build a **real-world GenAI application**, starting from data preprocessing and contextual enrichment to real-time content generation.



<img width="1536" height="1024" alt="ChatGPT Image Jan 4, 2026, 07_43_49 PM" src="https://github.com/user-attachments/assets/f346d08a-1dbe-4856-a34c-b89ea0751a55" />

---

## ‚ú® Features

* Generate professional LinkedIn posts instantly
* Topic-based content generation (Career, Job Search, Rejection, Motivation, etc.)
* Supports **Short, Medium, and Long** post formats
* Multi-language selection
* Context-aware responses using preprocessed post data
* Clean and responsive Streamlit UI
* Modular and extensible architecture

---

## üß† High-Level Architecture


<img width="2752" height="1536" alt="unnamed (3)" src="https://github.com/user-attachments/assets/d620d39d-e8fb-4c6b-95ef-ee5dac6aba71" />


The system is divided into **two main stages**:

### **Stage 1: Data Preparation**

* Raw LinkedIn posts are collected and stored in JSON format
* Posts are cleaned, structured, and enriched
* Metadata such as **topic, language, and length** is added
* Processed posts are stored for contextual grounding

### **Stage 2: Post Generation**

* User selects topic, language, and length from UI
* LangChain builds a structured prompt
* Llama 3.2 generates the LinkedIn post
* Output is displayed in real time in the Streamlit app

---

## üîÑ Data Processing Pipeline

1. Load raw LinkedIn posts from `raw_posts.json`
2. Clean and normalize text data
3. Structure posts with metadata (topic, engagement, etc.)
4. Save enriched posts into `processed_posts.json`
5. Use processed data as contextual examples during generation

This pipeline ensures **better relevance, tone consistency, and output quality**.

---

## üóÇÔ∏è Project Structure

```bash
LinkedIn-Post-Generator-Tool-Gen-AI-Project-Using-Llama/
‚îÇ
‚îú‚îÄ‚îÄ app.py                     # Main Streamlit application
‚îú‚îÄ‚îÄ preprocess.py              # Data preprocessing script
‚îú‚îÄ‚îÄ requirements.txt           # Project dependencies
‚îú‚îÄ‚îÄ README.md                  # Project documentation
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw_posts.json         # Raw LinkedIn posts
‚îÇ   ‚îî‚îÄ‚îÄ processed_posts.json  # Cleaned & enriched posts
‚îÇ
‚îú‚îÄ‚îÄ vectorstore/
‚îÇ   ‚îî‚îÄ‚îÄ chroma_db/             # Vector embeddings storage
‚îÇ
‚îú‚îÄ‚îÄ prompts/
‚îÇ   ‚îî‚îÄ‚îÄ prompt_templates.py   # LangChain prompt templates
‚îÇ
‚îî‚îÄ‚îÄ assets/
    ‚îî‚îÄ‚îÄ screenshots/           # Architecture & UI images
```

---

## üõ†Ô∏è Technologies Used

### **Programming & Frameworks**

* Python
* Streamlit

### **AI & GenAI**

* Llama 3.2
* LangChain

### **Data & Storage**

* JSON
* ChromaDB (Vector Database)

---

## ‚öôÔ∏è Core Technologies

* **Streamlit** ‚Äì Web-based UI for user interaction
* **LangChain** ‚Äì Prompt engineering and workflow orchestration
* **Vector Database (ChromaDB)** ‚Äì Context storage and retrieval
* **Llama 3.2** ‚Äì Large Language Model for text generation

---

## üìö Key Libraries

* `streamlit` ‚Äì UI rendering
* `langchain` ‚Äì Prompt management
* `json` ‚Äì Data handling
* `chromadb` ‚Äì Vector storage
* `python-dotenv` (optional) ‚Äì Environment configuration

---

## ü§ñ AI Model

* **Model Name:** Llama 3.2
* **Type:** Large Language Model (LLM)
* **Usage:**

  * Generates professional LinkedIn content
  * Uses contextual examples for better tone and relevance
  * Produces real-time outputs based on structured prompts

---

## üì¶ Installation

### üîß Prerequisites

* Python **3.8 or higher**
* Git
* Llama 3.2 model access (local or API-based, depending on setup)
* (Optional) Virtual environment tool (`venv` or `conda`)

---

### ‚öôÔ∏è Setup Steps

#### 1Ô∏è‚É£ Clone the Repository

```bash
git clone https://github.com/vennelabathini/LinkedIn-Post-Generator-Tool-Gen-AI-Project-Using-Llama.git
cd LinkedIn-Post-Generator-Tool-Gen-AI-Project-Using-Llama
```

---

#### 2Ô∏è‚É£ Create a Virtual Environment

```bash
python -m venv venv
```

Activate the environment:

* **Windows**

```bash
venv\Scripts\activate
```

* **macOS / Linux**

```bash
source venv/bin/activate
```

---

#### 3Ô∏è‚É£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

#### 4Ô∏è‚É£ Configure Environment Variables (Optional)

If your LLM setup requires API keys or environment configs:

Create a `.env` file in the project root:

```env
LLM_MODEL=llama-3.2
```

> Update variables based on your LLM provider or local setup.

---

#### 5Ô∏è‚É£ Prepare the Data (Optional)

If you want to reprocess LinkedIn post data:

```bash
python preprocess.py
```

This step:

* Loads raw LinkedIn posts
* Cleans and enriches data
* Saves processed posts for generation

---

#### 6Ô∏è‚É£ Run the Application

```bash
streamlit run app.py
```

---

#### 7Ô∏è‚É£ Access the Application

Open your browser and navigate to:

```text
http://localhost:8501
```



## üßæ Output

* A well-structured, professional LinkedIn post
* Content tailored to user-selected inputs
* Suitable for posting directly on LinkedIn

The output updates **in real time** with each generation.

<img width="1902" height="1033" alt="tool 1" src="https://github.com/user-attachments/assets/aba05999-e7d0-4575-9897-38b52d515317" />



---

## üîç How It Works (Step-by-Step)

1. User provides input through Streamlit UI
2. Inputs are passed to LangChain prompt templates
3. Contextual examples are retrieved from processed data
4. Llama 3.2 generates the LinkedIn post
5. The result is displayed on the UI

---

## ‚öôÔ∏è Configuration

* Update post categories in UI dropdowns
* Modify prompt templates for different writing styles
* Extend data in `raw_posts.json` for better context
* Adjust length rules for short/medium/long posts

---

## üéØ Use Cases

* Job seekers writing LinkedIn posts
* Career guidance and motivation content
* Influencer and professional branding
* Learning real-world GenAI application development

---


